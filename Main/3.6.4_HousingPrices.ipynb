{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Housing Prices\n",
    " ## Melbourne housing clearance data from Jan 2016\n",
    " Using this Kaggle data create a model to predict a house's value. We want to be able to understand what creates value in a house, as though we were a real estate developer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', '{:.2f}'.format)\n",
    "#import pandas_profiling as pp\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import seaborn as sns\n",
    "# Load models\n",
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "#### Soure: https://www.kaggle.com/anthonypino/melbourne-housing-market\n",
    "This data was scraped from publicly available results posted every week from Domain.com.au. The dataset includes Address, Type of Real estate, Suburb, Method of Selling, Rooms, Price, Real Estate Agent, Date of Sale and distance from C.B.D.\n",
    "\n",
    "#### Some Key Details\n",
    "* Suburb: Suburb\n",
    "* Address: Address\n",
    "* Rooms: Number of rooms\n",
    "* Price: Price in Australian dollars\n",
    "* Method: S - property sold; SP - property sold prior; PI - property passed in; PN - sold prior not disclosed; SN - sold not disclosed; NB - no bid; VB - vendor bid; W - withdrawn prior to auction; SA - sold after auction; SS - sold after auction price not disclosed. N/A - price or highest bid not available.\n",
    "* Type: br - bedroom(s); h - house,cottage,villa, semi,terrace; u - unit, duplex; t - townhouse; dev site - development site; o res - other residential.\n",
    "* SellerG: Real Estate Agent\n",
    "* Date: Date sold\n",
    "* Distance: Distance from CBD in Kilometres\n",
    "* Regionname: General Region (West, North West, North, North east ...etc)\n",
    "* Propertycount: Number of properties that exist in the suburb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/anthonypino/melbourne-housing-market/downloads/melbourne-housing-market.zip/27\n",
    "df = pd.read_csv(\"MELBOURNE_HOUSE_PRICES_LESS.csv\")\n",
    "# pp.ProfileReport(df, check_correlation=True).to_file(outputfile=\"3.6.4_ProfileOfHousingPrices_RAW.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Rooms  Price  Postcode  Propertycount  Distance\n",
      "Rooms           1.00   0.41      0.09          -0.06      0.28\n",
      "Price           0.41   1.00      0.01          -0.06     -0.25\n",
      "Postcode        0.09   0.01      1.00           0.00      0.50\n",
      "Propertycount  -0.06  -0.06      0.00           1.00      0.00\n",
      "Distance        0.28  -0.25      0.50           0.00      1.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop ca. 25% of rows which have a lot of missing values\n",
    "df = df.dropna(subset=['Price'])\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\n",
    "    'Address', # too many distinct values\n",
    "    'Date' # not necessary \n",
    "])\n",
    "# Drop duplicated\n",
    "df = df.drop_duplicates() # Dataset has 2 duplicate rows\n",
    "\n",
    "# Do second data profile report on cleaned data\n",
    "# pp.ProfileReport(df, check_correlation=False, pool_size=15).to_file(outputfile=\"3.6.4_ProfileOfHousingPrices_CLEAN.html\")\n",
    "# See the webpage at: https://github.com/RobKnop/ThinkfulDataScienceBootcamp/blob/master/Main/3.6.4_ProfileOfHousingPrices_CLEAN.html\n",
    "\n",
    "# Make the correlation matrix.\n",
    "corrmat = df.corr()\n",
    "print(corrmat)\n",
    "\n",
    "# Set up the matplotlib figure.\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "# Draw the heatmap using seaborn.\n",
    "sns.heatmap(corrmat, vmax=.8, square=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Findings\n",
    " 1. Correlation to y (Price) exists:\n",
    " 2. Multicollinearity is in general low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Our key evaluation metric to optimize on is R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Models to try:\n",
    " 1. Linear Regression\n",
    " 4. RandomForestRegressor\n",
    " 5. KNN\n",
    " 6. Support Vector Machine\n",
    " 7. GradientBoosting Regression\n",
    " 8. (Also use of KSelectBest, GridSearch, PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = df.drop(columns=[\n",
    "                    'Price', # is the Y\n",
    "                    'Suburb', # is categorical \n",
    "                    'SellerG', # is categorical \n",
    "                    'Type', # is categorical \n",
    "                    'Regionname', # is categorical \n",
    "                    'Method', # is categorical \n",
    "                    'CouncilArea', # is categorical,\n",
    "                    'Postcode' # is categorical,\n",
    "                    ])\n",
    "X = pd.concat([X, pd.get_dummies(df['Suburb'])], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['SellerG'])], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['Type'])], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['Regionname'])], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['Method'])], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['CouncilArea'])], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(df['Postcode'])], axis=1)\n",
    "\n",
    "y = df['Price']\n",
    "\n",
    "#Try SelectKBest\n",
    "X_selKBest = SelectKBest(k=300).fit_transform(X, y)\n",
    "\n",
    "# Use PCA (but it is not working better)\n",
    "sklearn_pca = PCA(n_components=300)\n",
    "X_pca = sklearn_pca.fit_transform(X)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean-squared:\n",
      "122543734878.8606\n",
      "rms error is: 350062.4728228667\n",
      "R^2 score:  0.6641821394463606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Score: 0.65 (+/- 0.03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:   12.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression: Instantiate and fit our model.\n",
    "regr = linear_model.LinearRegression()\n",
    "#print(data['Sales'].values)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Inspect the results.\n",
    "y_pred = regr.predict(X_test)\n",
    "print('\\nmean-squared:')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "rmse_val = rmse(y_pred, y_test)\n",
    "print(\"rms error is: \" + str(rmse_val))\n",
    "print('R^2 score: ', regr.score(X_test, y_test)) \n",
    "'''\n",
    "SelectKBest:\n",
    "    mean-squared: 1.856840390039477e+17\n",
    "    rms error is: 430910708.85271317\n",
    "    R^2 score:  -508846.0396214517\n",
    "PCA:\n",
    "    mean-squared: 122860775174.52856\n",
    "    rms error is: 350515.0141927284\n",
    "    R^2 score:  0.6633133247827161\n",
    "'''\n",
    "\n",
    "score = cross_val_score(regr, X, y, cv=5, n_jobs=2, verbose=1)\n",
    "print(\"Cross Validated Score: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "# Cross Validated Score: -100984196084.83 (+/- 391626543821.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k =  5\n",
      "KNN R^2 score:  0.7014093121118009\n",
      "KNN_dist R^2 score:  0.6710558334816799\n",
      "\n",
      "k =  6\n",
      "KNN R^2 score:  0.7064129505814168\n",
      "KNN_dist R^2 score:  0.6747098848039208\n",
      "\n",
      "k =  7\n",
      "KNN R^2 score:  0.7111650089094321\n",
      "KNN_dist R^2 score:  0.6766531841524128\n",
      "\n",
      "k =  8\n",
      "KNN R^2 score:  0.7132547118963987\n",
      "KNN_dist R^2 score:  0.6778336761097863\n",
      "\n",
      "k =  9\n",
      "KNN R^2 score:  0.7136270761913617\n",
      "KNN_dist R^2 score:  0.6788028150507541\n",
      "\n",
      "k =  10\n",
      "KNN R^2 score:  0.7145272990951117\n",
      "KNN_dist R^2 score:  0.6796816071048835\n",
      "\n",
      "k =  11\n",
      "KNN R^2 score:  0.7127739589559527\n",
      "KNN_dist R^2 score:  0.6786433343378238\n",
      "\n",
      "k =  12\n",
      "KNN R^2 score:  0.7122417252912688\n",
      "KNN_dist R^2 score:  0.6783618512798892\n",
      "\n",
      "k =  13\n",
      "KNN R^2 score:  0.7125661034209154\n",
      "KNN_dist R^2 score:  0.6780712939965223\n",
      "\n",
      "k =  14\n",
      "KNN R^2 score:  0.712794756959067\n",
      "KNN_dist R^2 score:  0.6782751324488101\n"
     ]
    }
   ],
   "source": [
    "# KNN:\n",
    "for k in range(5, 15, 1):\n",
    "    print('\\nk = ', k)\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    print('KNN R^2 score: ', knn.score(X_test, y_test)) \n",
    "    knn_w = KNeighborsRegressor(n_neighbors=k, weights='distance')\n",
    "    knn_w.fit(X_train, y_train)\n",
    "    print('KNN_dist R^2 score: ', knn_w.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "score = cross_val_score(KNeighborsRegressor(n_neighbors=k), X, y, cv=5, n_jobs=-1)\n",
    "print(\"Unweighted Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "score_w = cross_val_score(KNeighborsRegressor(n_neighbors=k, weights='distance'), X, y, cv=5, n_jobs=-1)\n",
    "print(\"Weighted Accuracy: %0.2f (+/- %0.2f)\" % (score_w.mean(), score_w.std() * 2))\n",
    "\"\"\"\n",
    "SelectKBest:\n",
    "    Best k =  7\n",
    "    KNN R^2 score:  0.7175245604677205\n",
    "    KNN_dist R^2 score:  0.6813617988109184\n",
    "PCA:\n",
    "    k =  10\n",
    "    KNN R^2 score:  0.7145272990951117\n",
    "    KNN_dist R^2 score:  0.6796816071048835\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:  4.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  64 | elapsed:    2.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=13,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=5, min_samples_split=5,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor:\n",
    "# Random Forest: \n",
    "rfr = ensemble.RandomForestRegressor(n_jobs=-1, verbose=1)\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {'n_estimators': [16, 32, 64], \n",
    "              #'max_features': ['log2', 'sqrt','auto'], \n",
    "              'max_depth': [5, 10, 13], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1, 2, 5]\n",
    "             }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rfr, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_obj.fit(X, y)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "grid_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  32 | elapsed:    8.3s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   2 out of  32 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done  32 out of  32 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   2 out of  32 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done  32 out of  32 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean-squared:\n",
      "98700676539.66922\n",
      "rms error is: 314166.6381710024\n",
      "RandomForest R^2 score:  0.7295214637980953\n",
      "Cross Validated Score: 0.73 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# Run best model:\n",
    "rfr = ensemble.RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=13,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=5, min_samples_split=3,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=32, n_jobs=-1,\n",
    "           oob_score=False, random_state=None, verbose=1, warm_start=False)\n",
    "\n",
    "rfr.fit(X_train, y_train) \n",
    "y_pred = rfr.predict(X_test)\n",
    "print('\\nmean-squared:')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "rmse_val = rmse(y_pred, y_test)\n",
    "print(\"rms error is: \" + str(rmse_val))\n",
    "print('RandomForest R^2 score: ', rfr.score(X_test, y_test)) \n",
    "'''\n",
    "SelectKBest:\n",
    "    mean-squared: 92676682719.69162\n",
    "    rms error is: 304428.452546229\n",
    "    RandomForest R^2 score:  0.7460295677710402\n",
    "PCA:\n",
    "    mean-squared: 99371423200.81209\n",
    "    rms error is: 315232.3320993773\n",
    "    RandomForest R^2 score:  0.7276833550694755\n",
    "'''\n",
    "score = cross_val_score(rfr, X, y, cv=5, n_jobs=-1)\n",
    "print(\"Cross Validated Score: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "# Cross Validated Score: 0.73 (+/- 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]\n",
      "mean-squared:\n",
      "392972375356.1207\n",
      "rms error is: 626875.0875223251\n",
      "SVM R^2 score:  -0.0768983210706693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nKSelectBest\\n    mean-squared: 392966474010.09644\\n    SVM R^2 score:  -0.07688214906972424\\nPCA:\\n    mean-squared: 392920464076.49603 \\n    rms error is: 626833.6813513582\\n    SVM R^2 score:  -0.07675606381957945\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM: \n",
    "svr = SVR(\n",
    "        kernel='rbf', \n",
    "        degree=3, \n",
    "        gamma='scale', \n",
    "        coef0=0.0, tol=0.001, \n",
    "        C=1.0, \n",
    "        epsilon=0.1, \n",
    "        shrinking=True, \n",
    "        cache_size=200, \n",
    "        verbose=1, \n",
    "        max_iter=-1\n",
    "        )\n",
    "\n",
    "svr.fit(X_train, y_train) \n",
    "y_pred = svr.predict(X_test)\n",
    "print('\\nmean-squared:')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "rmse_val = rmse(y_pred, y_test)\n",
    "print(\"rms error is: \" + str(rmse_val))\n",
    "print('SVM R^2 score: ', svr.score(X_test, y_test)) \n",
    "'''\n",
    "KSelectBest\n",
    "    mean-squared: 392966474010.09644\n",
    "    SVM R^2 score:  -0.07688214906972424\n",
    "PCA:\n",
    "    mean-squared: 392920464076.49603 \n",
    "    rms error is: 626833.6813513582\n",
    "    SVM R^2 score:  -0.07675606381957945\n",
    "'''\n",
    "# score = cross_val_score(svr, X, y, cv=5, n_jobs=-1)\n",
    "# print(\"Cross Validated Score: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "# No result, because never tried. R^2 is allready really bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed: 12.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=10, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=5,\n",
       "             min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=40, n_iter_no_change=50, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting:\n",
    "gbr = ensemble.GradientBoostingRegressor(n_estimators=40, n_iter_no_change=50)\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "              'max_depth': [3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1, 2, 5]\n",
    "             }\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(gbr, parameters, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_obj.fit(X, y)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "gbr = grid_obj.best_estimator_\n",
    "gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1 294624871976.7645            8.20m\n",
      "         2 251740351447.7878            8.18m\n",
      "         3 219403660835.7612            8.18m\n",
      "         4 198161859638.0079            8.14m\n",
      "         5 181559262095.7960            8.14m\n",
      "         6 169966467929.8924            8.12m\n",
      "         7 160022858563.6874            8.11m\n",
      "         8 151997265582.5010            8.10m\n",
      "         9 146112440412.3065            8.07m\n",
      "        10 141009994071.3567            8.06m\n",
      "        20 115709841334.4096            7.83m\n",
      "        30 105736061889.1082            7.68m\n",
      "        40 100728789562.7135            7.54m\n",
      "        50 96958141053.1474            7.38m\n",
      "        60 94175709839.3095            7.24m\n",
      "        70 91978887299.2244            7.09m\n",
      "        80 89532631938.2481            6.96m\n",
      "        90 87824124370.2314            6.82m\n",
      "       100 86674692203.2416            6.67m\n",
      "       200 77618284491.6246            5.31m\n",
      "\n",
      "mean-squared:\n",
      "98300171062.5238\n",
      "rms error is: 313528.5809340577\n",
      "Gradient Boost R^2 score:  0.73061900577042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Score: 0.74 (+/- 0.03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 19.6min finished\n"
     ]
    }
   ],
   "source": [
    "#Run best model\n",
    "gbr = ensemble.GradientBoostingRegressor(\n",
    "                        loss='ls', \n",
    "                        learning_rate=0.2, \n",
    "                        n_estimators=600, \n",
    "                        subsample=1.0, \n",
    "                        criterion='friedman_mse', \n",
    "                        min_samples_split=5, \n",
    "                        min_samples_leaf=5, \n",
    "                        min_weight_fraction_leaf=0.0, \n",
    "                        max_depth=3, \n",
    "                        min_impurity_decrease=0.0, \n",
    "                        min_impurity_split=None, \n",
    "                        init=None, \n",
    "                        random_state=None, \n",
    "                        max_features=None, \n",
    "                        alpha=0.9, \n",
    "                        verbose=1, \n",
    "                        max_leaf_nodes=None, \n",
    "                        warm_start=False, \n",
    "                        presort='auto', \n",
    "                        validation_fraction=0.1, \n",
    "                        n_iter_no_change=50, \n",
    "                        tol=0.0001\n",
    "                        )\n",
    "gbr.fit(X_train, y_train) \n",
    "y_pred = gbr.predict(X_test)\n",
    "print('\\nmean-squared:')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "rmse_val = rmse(y_pred, y_test)\n",
    "print(\"rms error is: \" + str(rmse_val))\n",
    "print('Gradient Boost R^2 score: ', gbr.score(X_test, y_test)) \n",
    "'''\n",
    "SelectKBest:\n",
    "    mean-squared: 93107157557.86372\n",
    "    Gradient Boost R^2 score:  0.7448498980039971\n",
    "PCA:\n",
    "    mean-squared: 96927080172.55779\n",
    "    rms error is: 311331.1423108163\n",
    "    Gradient Boost R^2 score:  0.7343818129467305\n",
    "'''\n",
    "\n",
    "score = cross_val_score(gbr, X, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Cross Validated Score: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model evaluation:\n",
    "Both models (Random Forest and Gradient Boosting) performed best with R^2 score of 0.74.  \n",
    "Because Random Forest is faster to compute, this model would be chose over Gradient Boosting."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
