{"cells":[{"source":"# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\n# ms-python.python added\nimport os\ntry:\n\tos.chdir(os.path.join(os.getcwd(), '..'))\n\tprint(os.getcwd())\nexcept:\n\tpass\n","cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","metadata":{},"source":[" # Amazon Reviews\n"," Use one of the following datasets to perform sentiment analysis on the given Amazon reviews. Pick one of the \"small\" datasets that is a reasonable size for your computer. The goal is to create a model to algorithmically predict if a review is positive or negative just based on its text. Try to see how these reviews compare across categories. Does a review classification model for one category work for another?"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["import os\n","from IPython import get_ipython\n","import pandas as pd\n","pd.set_option('float_format', '{:.2f}'.format)\n","import pandas_profiling as pp\n","import numpy as np\n","import scipy\n","import matplotlib.pyplot as plt\n","get_ipython().run_line_magic('matplotlib', 'inline')\n","import seaborn as sns\n","# Load models\n","from sklearn import ensemble, tree\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import BernoulliNB\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.decomposition import TruncatedSVD \n","from sklearn.utils import shuffle\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",""]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["import gzip\n","\n","def parse(path):\n","  g = gzip.open(path, 'rb')\n","  for l in g:\n","    yield eval(l)\n","\n","def getDF(path):\n","  i = 0\n","  df = {}\n","  for d in parse(path):\n","    df[i] = d\n","    i += 1\n","  return pd.DataFrame.from_dict(df, orient='index')\n","\n","# Read data\n","# filepath = 'Main/data/amazon-reviews/reviews_Home_and_Kitchen_5.json.gz'\n","filepath = 'reviews_Home_and_Kitchen_5.json.gz'\n","df = getDF(filepath)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### Variable descriptions\n"," * reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n"," * asin - ID of the product, e.g. 0000013714\n"," * reviewerName - name of the reviewer\n"," * helpful - helpfulness rating of the review, e.g. 2/3\n"," * reviewText - text of the review\n"," * overall - rating of the product\n"," * summary - summary of the review\n"," * unixReviewTime - time of the review (unix time)\n"," * reviewTime - time of the review (raw)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["# Do first data profile report on raw data\n","# pp.ProfileReport(df, check_correlation=False, pool_size=15).to_file(outputfile=\"3.6.3_AmazonReviews_RAW.html\")\n","# https://github.com/RobKnop/ThinkfulDataScienceBootcamp/blob/master/Main/3.6.3_AmazonReviews_RAW.html\n",""]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# Drop unnecessary columns\n","df = df.drop(columns=[\n","    'reviewerID',\n","    'asin', # \n","    'reviewerName', # \n","    'helpful', # \n","    'unixReviewTime', \n","    'reviewTime' # \n","])\n","# Define the Y\n","df['y_sentiment'] = np.where(df['overall'] >= 4.0 , 1, 0)\n","df = df.drop(columns=['overall'])\n","# Drop duplicated\n","df = df.drop_duplicates() # Dataset has 70 duplicate rows"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["# Do second data profile report on cleaned data\n","# pp.ProfileReport(df, check_correlation=False, pool_size=15).to_file(outputfile=\"3.6.3_AmazonReviews_CLEAN.html\")\n","# See the webpage at: https://github.com/RobKnop/ThinkfulDataScienceBootcamp/blob/master/Main/3.6.3_AmazonReviews_CLEAN_5mio.html\n",""]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# Feature Engineering\n","df['space'] = ' '\n","df['corpus'] = df['summary'] + df['space'] + df['reviewText']\n","df = df.drop(columns=[\n","    'summary',\n","    'reviewText',\n","    'space'\n","])\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Findings\n"," 1. Correlation to y (delayed) exists:\n"," 2. Multicollinearity is in general low, but certain variables are highly correlated\n","   * like DEP_xxxx vars\n","   * DISTANCE - DISTANCE_GROUP - AIR_TIME\n"," 3. Class imbalance: 17601697 - 2398303 (88%/12%)"]},{"cell_type":"markdown","metadata":{},"source":[" #### Our key evaluation metric to optimize on is accuracy, followed by the f1 score\n"," * A balance between precision and recall is needed."]},{"cell_type":"markdown","metadata":{},"source":[" #### Models to try:\n"," 1. LogisticRegression\n"," 2. Descion Tree\n"," 3. Naive Bayes\n"," 4. RandomForestClassifier\n"," 5. KNN\n"," 6. Support Vector Machine\n"," 7. GradientBoostingClassifier\n"," 8. (Also use of KSelectBest, GridSearch)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Random under-sampling:\n1    96475\n0    96475\nName: y_sentiment, dtype: int64\n"}],"source":["#Class Balancing via Under-Sampling\n","count_class_0, count_class_1 = df.y_sentiment.value_counts()\n","\n","# Divide by class\n","df_class_0 = df[df['y_sentiment'] == 1]\n","df_class_1 = df[df['y_sentiment'] == 0]\n","print('Random under-sampling:')\n","df_class_0_under = df_class_0.sample(count_class_1)\n","df = pd.concat([df_class_0_under, df_class_1], axis=0)\n","print(df.y_sentiment.value_counts())\n","\n","# Define X and y\n","X = TfidfVectorizer().fit_transform(df.corpus)\n","y = df['y_sentiment']\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",""]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.3s finished\n"},{"name":"stdout","output_type":"stream","text":"Confusion Matrix\n Predicted      0      1    All\nTrue                          \n0          16947   2295  19242\n1           2514  16834  19348\nAll        19461  19129  38590\nLG:\n               precision    recall  f1-score   support\n\n           0       0.87      0.88      0.88     19242\n           1       0.88      0.87      0.88     19348\n\n   micro avg       0.88      0.88      0.88     38590\n   macro avg       0.88      0.88      0.88     38590\nweighted avg       0.88      0.88      0.88     38590\n\n\nAUC:  0.8753968715968448\n"},{"name":"stdout","output_type":"stream","text":"\f1:  [0.86613112 0.87305001 0.87284271 0.87074372 0.8576056 ]\nCross Validated f1: 0.868 (+/- 0.012)\n"}],"source":["# Logistic Regression: \n","lr = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=50, verbose=1, n_jobs=-1)\n","\n","# Fit the model.\n","fit = lr.fit(X_train, y_train)\n","\n","# Display.\n","y_pred = fit.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('LG:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('\\nAUC: ', auc(fpr, tpr))\n","\"\"\"\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","\n","Under-Sampling:\n","           0       0.87      0.88      0.87     19242\n","           1       0.88      0.87      0.87     19348\n","\"\"\"\n","score = cross_val_score(fit, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n","print('\\f1: ', score)\n","print(\"Cross Validated f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","# Cross Validated f1: 0.87 (+/- 0.01)\n",""]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   10.5s\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 378 tasks      | elapsed:   26.6s\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 728 tasks      | elapsed:   49.0s\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  1.2min finished\n"},{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n            max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=1,\n            min_samples_split=3, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')"},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# Decision Tree:\n","dt = tree.DecisionTreeClassifier()\n","parameters = { \n","              'max_features': [1, 2, 3], \n","              'criterion': ['entropy', 'gini'],\n","              'max_depth': [2, 3, 5, 10, 13], \n","              'min_samples_split': [2, 3, 5],\n","              'min_samples_leaf': [1, 3, 5, 8]\n","             }\n","# Run the grid search\n","grid_obj = GridSearchCV(dt, parameters, scoring='accuracy', cv=3, n_jobs=-1, verbose=1)\n","grid_obj.fit(X, y)\n","dt = grid_obj.best_estimator_\n","dt\n",""]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=13,\n            max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=5,\n            min_samples_split=3, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')"},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["#Run best DT model:\n","\n","dt = tree.DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=13,\n","            max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,\n","            min_impurity_split=None, min_samples_leaf=5,\n","            min_samples_split=3, min_weight_fraction_leaf=0.0,\n","            presort=False, random_state=None, splitter='best')\n","\n","# Fit the best algorithm to the data. \n","dt.fit(X_train, y_train)\n",""]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Confusion Matrix\n Predicted      0    All\nTrue                   \n0          19242  19242\n1          19348  19348\nAll        38590  38590\nDT:\n               precision    recall  f1-score   support\n\n           0       0.50      1.00      0.67     19242\n           1       0.00      0.00      0.00     19348\n\n   micro avg       0.50      0.50      0.50     38590\n   macro avg       0.25      0.50      0.33     38590\nweighted avg       0.25      0.50      0.33     38590\n\nAUC:  0.5\nDT: Input X --> f1: 0.500 (+/- 0.000)\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    1.0s remaining:    1.0s\n[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.0s finished\n"}],"source":["# Evaluate\n","y_pred = dt.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('DT:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","\"\"\"\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","\n","Under-Sampling:\n","           0       0.50      1.00      0.67     19242\n","           1       0.00      0.00      0.00     19348\n","\"\"\"\n","score = cross_val_score(dt, X, y, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"DT: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","# DT: Input X --> f1: 0.810 (+/- 0.029)\n",""]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Confusion Matrix\n Predicted      0      1    All\nTrue                          \n0          11128   8114  19242\n1           3643  15705  19348\nAll        14771  23819  38590\nBNB:\n               precision    recall  f1-score   support\n\n           0       0.75      0.58      0.65     19242\n           1       0.66      0.81      0.73     19348\n\n   micro avg       0.70      0.70      0.70     38590\n   macro avg       0.71      0.70      0.69     38590\nweighted avg       0.71      0.70      0.69     38590\n\nAUC:  0.6950150334863112\nBNB: Input X --> f1: 0.689 (+/- 0.028)\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.8s remaining:    0.8s\n[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.8s finished\n"}],"source":["# Naive Bayes:\n","bnb = BernoulliNB()\n","# Fit our model to the data.\n","bnb.fit(X_train, y_train)\n","\n","# Evaluate\n","y_pred = bnb.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('BNB:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","\"\"\"\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","\n","Under-Sampling:\n","           0       0.75      0.58      0.65     19242\n","           1       0.66      0.81      0.72     19348\n","\"\"\"\n","score = cross_val_score(bnb, X, y, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"BNB: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","#BNB: Input X --> f1: 0.810 (+/- 0.005)\n",""]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   13.7s\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  1.6min\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=10)]: Done 243 out of 243 | elapsed:  2.3min finished\n"},{"data":{"text/plain":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=13, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=5, min_samples_split=5,\n            min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)"},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["# Random Forest: \n","rfc = ensemble.RandomForestClassifier(criterion='entropy', n_jobs=-1)\n","\n","# Choose some parameter combinations to try\n","parameters = {'n_estimators': [16, 32, 64], \n","              #'max_features': ['log2', 'sqrt','auto'], \n","              #'criterion': ['entropy', 'gini'],\n","              'max_depth': [5, 10, 13], \n","              'min_samples_split': [2, 3, 5],\n","              'min_samples_leaf': [1, 2, 5]\n","             }\n","\n","# Run the grid search\n","grid_obj = GridSearchCV(rfc, parameters, scoring='accuracy', cv=3, n_jobs=10, verbose=1)\n","grid_obj.fit(X, y)\n","\n","# Set the clf to the best combination of parameters\n","rfc = grid_obj.best_estimator_\n","rfc"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=13, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=5, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)"},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["# Run best model:\n","rfc = ensemble.RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","            max_depth=13, max_features='auto', max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=5, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n","            oob_score=False, random_state=None, verbose=0,\n","            warm_start=False)\n","\n","# Fit the best algorithm to the data. \n","rfc.fit(X_train, y_train)\n",""]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Confusion Matrix\n Predicted      0      1    All\nTrue                          \n0          13637   5605  19242\n1           4437  14911  19348\nAll        18074  20516  38590\nRFC:\n               precision    recall  f1-score   support\n\n           0       0.75      0.71      0.73     19242\n           1       0.73      0.77      0.75     19348\n\n   micro avg       0.74      0.74      0.74     38590\n   macro avg       0.74      0.74      0.74     38590\nweighted avg       0.74      0.74      0.74     38590\n\nAUC:  0.7396920423818779\nRFC: Input X --> f1: 0.741 (+/- 0.021)\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   14.2s remaining:   14.2s\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   15.1s finished\n"}],"source":["y_pred = rfc.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('RFC:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","'''\n","Without Under-Sampling:\n","              precision    recall  f1-score   support\n","\n","Under-Sampling:\n","           0       0.75      0.75      0.75     19242\n","           1       0.75      0.75      0.75     19348\n","'''\n","score = cross_val_score(rfc, X, y, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"RFC: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","# RFC: Input X --> f1: 0.739 (+/- 0.024)\n",""]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"      Iter       Train Loss   Remaining Time \n         1           1.2863           13.04m\n         2           1.2371           12.78m\n         3           1.1892           12.61m\n         4           1.1575           12.46m\n         5           1.1352           12.32m\n         6           1.1166           12.19m\n         7           1.1012           12.05m\n         8           1.0865           11.92m\n         9           1.0729           11.79m\n        10           1.0588           11.66m\n        20           0.9625           10.35m\n        30           0.9065            9.06m\n        40           0.8685            7.78m\n        50           0.8378            6.48m\n        60           0.8148            5.17m\n        70           0.7960            3.87m\n        80           0.7800            2.58m\n        90           0.7654            1.29m\n       100           0.7529            0.00s\nConfusion Matrix\n Predicted     0     1    All\nTrue                        \n0          8196  1486   9682\n1          1647  7966   9613\nAll        9843  9452  19295\nGradBoost:\n               precision    recall  f1-score   support\n\n           0       0.83      0.85      0.84      9682\n           1       0.84      0.83      0.84      9613\n\n   micro avg       0.84      0.84      0.84     19295\n   macro avg       0.84      0.84      0.84     19295\nweighted avg       0.84      0.84      0.84     19295\n\nAUC:  0.8375944121148862\nGradBoost: Input X --> f1: 0.834 (+/- 0.009)\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed: 14.1min remaining: 14.1min\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 14.2min finished\n"},{"data":{"text/plain":"'\\nGradBoost: Input X --> f1: 0.987 (+/- 0.004) - elapsed: 12.4min\\n'"},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=20)\n","# Gradient Boosting\n","# We'll make 100 iterations, use 2-deep trees, and set our loss function.\n","params = {'n_estimators': 100,\n","          'max_depth': 2,\n","          'loss': 'deviance',\n","          'verbose': 1,\n","          'n_iter_no_change': 50, \n","          'validation_fraction': 0.1,\n","          'learning_rate': 0.5\n","          }\n","\n","# Initialize and fit the model.\n","gbc = ensemble.GradientBoostingClassifier(**params)\n","gbc.fit(X_train, y_train)\n","\n","y_pred = gbc.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('GradBoost:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","# Best:\n","'''\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","Under-Sampling\n","           0       0.83      0.85      0.84      9682\n","           1       0.84      0.83      0.83      9613\n","'''\n","score = cross_val_score(gbc, X, y, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"GradBoost: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","\"\"\"\n","GradBoost: Input X --> f1: 0.987 (+/- 0.004) - elapsed: 12.4min\n","\"\"\""]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["# Reduce dims\n","sklearn_tSVD = TruncatedSVD(n_components=5)\n","X_tSVD = sklearn_tSVD.fit_transform(X)\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tSVD, y, test_size=0.2, random_state=20)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[LibSVM]Confusion Matrix\n Predicted      0      1    All\nTrue                          \n0          15940   3302  19242\n1           7183  12165  19348\nAll        23123  15467  38590\nSVC:\n               precision    recall  f1-score   support\n\n           0       0.69      0.83      0.75     19242\n           1       0.79      0.63      0.70     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.74      0.73      0.73     38590\nweighted avg       0.74      0.73      0.73     38590\n\nAUC:  0.7285716869692115\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"}],"source":["scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n","X_train = scaling.transform(X_train)\n","X_test = scaling.transform(X_test)\n","# SVM:\n","svc = SVC(gamma='scale', verbose=1)\n","y_test\n","svc.fit(X_train, y_train)\n","\n","y_pred = svc.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('SVC:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","'''\n","               precision    recall  f1-score   support\n","           0       0.69      0.82      0.75     19242\n","           1       0.78      0.63      0.70     19348\n","'''\n","score = cross_val_score(svc, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"Input X_train --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","# Input X_train --> f1: 0.727 (+/- 0.005)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# KNN:\n","for k in range(5, 25, 1):\n","    print('k = ', k)\n","    neighbors = KNeighborsClassifier(n_neighbors=k, n_jobs=-1, weights='distance')\n","    neighbors.fit(X_train, y_train)\n","    y_pred = neighbors.predict(X_test)\n","    #print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","    print('KNN:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","    #fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","    #print('AUC: ', auc(fpr, tpr))\n","    # Cross Validation\n","    #score = cross_val_score(neighbors, X_test, y_test, cv=5, scoring='accuracy', n_jobs=-1)\n","    #print(\"KNN: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","'''\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","k=19\n","Under-Sampling\n","           0       0.70      0.77      0.74     19242\n","           1       0.75      0.67      0.71     19348\n","'''\n",""]},{"cell_type":"markdown","metadata":{},"source":[" #### Final model evaluation:\n"," The best model logistic regression with a f1-score of 0.87.\n","### Other models\n"," * SVM cannot has decent results and is not fast to compute.\n"," * KNN has a similar problem. It gets harder for KNN to process a lot of data points.\n"," * A single Decision tree is not working because vectorized data.\n"," * RandomForest is better but with decent results.\n"," * Naive Bayes is really fast to compute but the results are bad.\n"," * Gradient Boosting the second best model."]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}