{"cells":[{"source":"# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\n# ms-python.python added\nimport os\ntry:\n\tos.chdir(os.path.join(os.getcwd(), '..'))\n\tprint(os.getcwd())\nexcept:\n\tpass\n","cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","metadata":{},"source":[" # Amazon Reviews\n"," Use one of the following datasets to perform sentiment analysis on the given Amazon reviews. Pick one of the \"small\" datasets that is a reasonable size for your computer. The goal is to create a model to algorithmically predict if a review is positive or negative just based on its text. Try to see how these reviews compare across categories. Does a review classification model for one category work for another?"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","from IPython import get_ipython\n","import pandas as pd\n","pd.set_option('float_format', '{:.2f}'.format)\n","import pandas_profiling as pp\n","import numpy as np\n","import scipy\n","import matplotlib.pyplot as plt\n","get_ipython().run_line_magic('matplotlib', 'inline')\n","import seaborn as sns\n","# Load models\n","from sklearn import ensemble, tree\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import BernoulliNB\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD \n","from sklearn.utils import shuffle\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n","\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import gzip\n","\n","def parse(path):\n","  g = gzip.open(path, 'rb')\n","  for l in g:\n","    yield eval(l)\n","\n","def getDF(path):\n","  i = 0\n","  df = {}\n","  for d in parse(path):\n","    df[i] = d\n","    i += 1\n","  return pd.DataFrame.from_dict(df, orient='index')\n","\n","# Read data\n","# filepath = 'Main/data/amazon-reviews/reviews_Home_and_Kitchen_5.json.gz'\n","filepath = 'reviews_Home_and_Kitchen_5.json.gz'\n","df = getDF(filepath)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# * reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n","# * asin - ID of the product, e.g. 0000013714\n","# * reviewerName - name of the reviewer\n","# * helpful - helpfulness rating of the review, e.g. 2/3\n","# * reviewText - text of the review\n","# * overall - rating of the product\n","# * summary - summary of the review\n","# * unixReviewTime - time of the review (unix time)\n","# * reviewTime - time of the review (raw)\n","\n","#%%\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# pp.ProfileReport(df, check_correlation=False, pool_size=15).to_file(outputfile=\"3.6.3_AmazonReviews_RAW.html\")\n","# https://github.com/RobKnop/ThinkfulDataScienceBootcamp/blob/master/Main/3.6.3_AmazonReviews_RAW.html\n","#%%\n","# Drop unnecessary columns"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["df = df.drop(columns=[\n","    'reviewerID',\n","    'asin', # \n","    'reviewerName', # \n","    'helpful', # \n","    'unixReviewTime', \n","    'reviewTime' # \n","])\n","# Define the Y\n","df['y_sentiment'] = np.where(df['overall'] >= 4.0 , 1, 0)\n","df = df.drop(columns=['overall'])\n","# Drop duplicated\n","df = df.drop_duplicates() # Dataset has 70 duplicate rows\n","#%%\n","# Do second data profile report on cleaned data"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# pp.ProfileReport(df, check_correlation=False, pool_size=15).to_file(outputfile=\"3.6.3_AmazonReviews_CLEAN.html\")\n","# See the webpage at: https://github.com/RobKnop/ThinkfulDataScienceBootcamp/blob/master/Main/3.6.3_AmazonReviews_CLEAN_5mio.html\n","#%%\n","# Feature Engineering"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["df['space'] = ' '\n","df['corpus'] = df['summary'] + df['space'] + df['reviewText']\n","df = df.drop(columns=[\n","    'summary',\n","    'reviewText',\n","    'space'\n","])\n","#%% [markdown]\n","# "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# 1. Correlation to y (delayed) exists: \n","# 2. Multicollinearity is in general low, but certain variables are highly correlated\n","#   * like DEP_xxxx vars\n","#   * DISTANCE - DISTANCE_GROUP - AIR_TIME\n","# 3. Class imbalance: 17601697 - 2398303 (88%/12%)\n","#%% [markdown]\n","# #### Our key evaluation metric to optimize on is"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# * A balance between precision and recall is needed. \n","#%% [markdown]\n","# #### Models to try:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# 1. LogisticRegression\n","# 2. Descion Tree \n","# 3. Naive Bayes \n","# 4. RandomForestClassifier\n","# 5. KNN\n","# 6. Support Vector Machine\n","# 7. GradientBoostingClassifier\n","# 8. (Also use of KSelectBest, GridSearch)\n","#%%\n","#Class Balancing via Under-Sampling"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Random under-sampling:\n1    96475\n0    96475\nName: y_sentiment, dtype: int64\n"}],"source":["count_class_0, count_class_1 = df.y_sentiment.value_counts()\n","\n","# Divide by class\n","df_class_0 = df[df['y_sentiment'] == 1]\n","df_class_1 = df[df['y_sentiment'] == 0]\n","print('Random under-sampling:')\n","df_class_0_under = df_class_0.sample(count_class_1)\n","df = pd.concat([df_class_0_under, df_class_1], axis=0)\n","print(df.y_sentiment.value_counts())\n","\n","# Define X and y\n","X = TfidfVectorizer().fit_transform(df.corpus)\n","y = df['y_sentiment']\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n","#%%\n","# Logistic Regression: "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    4.7s finished\n"},{"name":"stdout","output_type":"stream","text":"Confusion Matrix\n Predicted      0      1    All\nTrue                          \n0          16905   2337  19242\n1           2521  16827  19348\nAll        19426  19164  38590\nLG:\n               precision    recall  f1-score   support\n\n           0       0.87      0.88      0.87     19242\n           1       0.88      0.87      0.87     19348\n\n   micro avg       0.87      0.87      0.87     38590\n   macro avg       0.87      0.87      0.87     38590\nweighted avg       0.87      0.87      0.87     38590\n\n\nAUC:  0.8741246117022673\n"},{"name":"stdout","output_type":"stream","text":"\f1:  [0.86434309 0.87061415 0.87152112 0.86721949 0.85827935]\nCross Validated f1: 0.866 (+/- 0.010)\n"}],"source":["lr = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=50, verbose=1, n_jobs=-1)\n","\n","# Fit the model.\n","fit = lr.fit(X_train, y_train)\n","\n","# Display.\n","y_pred = fit.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('LG:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('\\nAUC: ', auc(fpr, tpr))\n","\"\"\"\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","\n","Under-Sampling:\n","           0       0.87      0.88      0.87     19242\n","           1       0.88      0.87      0.87     19348\n","\"\"\"\n","score = cross_val_score(fit, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n","print('\\f1: ', score)\n","print(\"Cross Validated f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","# Cross Validated f1: 0.87 (+/- 0.01)\n","#%%\n","# Decision Tree:"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:   10.1s\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 378 tasks      | elapsed:   25.7s\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 728 tasks      | elapsed:   47.5s\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  1.1min finished\n"},{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=13,\n            max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=1,\n            min_samples_split=3, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["dt = tree.DecisionTreeClassifier()\n","parameters = { \n","              'max_features': [1, 2, 3], \n","              'criterion': ['entropy', 'gini'],\n","              'max_depth': [2, 3, 5, 10, 13], \n","              'min_samples_split': [2, 3, 5],\n","              'min_samples_leaf': [1, 3, 5, 8]\n","             }\n","# Run the grid search\n","grid_obj = GridSearchCV(dt, parameters, scoring='accuracy', cv=3, n_jobs=-1, verbose=1)\n","grid_obj.fit(X, y)\n","dt = grid_obj.best_estimator_\n","dt\n","#%%\n","#R"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":"DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=13,\n            max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=5,\n            min_samples_split=3, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')"},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["\n","dt = tree.DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=13,\n","            max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0,\n","            min_impurity_split=None, min_samples_leaf=5,\n","            min_samples_split=3, min_weight_fraction_leaf=0.0,\n","            presort=False, random_state=None, splitter='best')\n","\n","# Fit the best algorithm to the data. \n","dt.fit(X_train, y_train)\n","#%%\n","# Evaluate"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Confusion Matrix\n Predicted      0    All\nTrue                   \n0          19242  19242\n1          19348  19348\nAll        38590  38590\nDT:\n               precision    recall  f1-score   support\n\n           0       0.50      1.00      0.67     19242\n           1       0.00      0.00      0.00     19348\n\n   micro avg       0.50      0.50      0.50     38590\n   macro avg       0.25      0.50      0.33     38590\nweighted avg       0.25      0.50      0.33     38590\n\nAUC:  0.5\nDT: Input X --> f1: 0.500 (+/- 0.000)\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    1.1s remaining:    1.1s\n[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.1s finished\n"}],"source":["y_pred = dt.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('DT:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","\"\"\"\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","\n","Under-Sampling:\n","           0       0.50      1.00      0.67     19242\n","           1       0.00      0.00      0.00     19348\n","\"\"\"\n","score = cross_val_score(dt, X, y, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"DT: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","# DT: Input X --> f1: 0.810 (+/- 0.029)\n","#%%\n","# Naive Bayes:"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Confusion Matrix\n Predicted      0      1    All\nTrue                          \n0          11078   8164  19242\n1           3681  15667  19348\nAll        14759  23831  38590\nBNB:\n               precision    recall  f1-score   support\n\n           0       0.75      0.58      0.65     19242\n           1       0.66      0.81      0.73     19348\n\n   micro avg       0.69      0.69      0.69     38590\n   macro avg       0.70      0.69      0.69     38590\nweighted avg       0.70      0.69      0.69     38590\n\nAUC:  0.692733778598376\nBNB: Input X --> f1: 0.688 (+/- 0.028)\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.8s remaining:    0.8s\n[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.8s finished\n"}],"source":["bnb = BernoulliNB()\n","# Fit our model to the data.\n","bnb.fit(X_train, y_train)\n","\n","# Evaluate\n","y_pred = bnb.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('BNB:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","\"\"\"\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","\n","Under-Sampling:\n","           0       0.75      0.58      0.65     19242\n","           1       0.66      0.81      0.72     19348\n","\"\"\"\n","score = cross_val_score(bnb, X, y, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"BNB: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","#BNB: Input X --> f1: 0.810 (+/- 0.005)\n","#%%\n","# Random Forest: "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   13.4s\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  1.5min\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=10)]: Done 243 out of 243 | elapsed:  2.2min finished\n"},{"data":{"text/plain":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=13, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=2, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)"},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["rfc = ensemble.RandomForestClassifier(criterion='entropy', n_jobs=-1)\n","\n","# Choose some parameter combinations to try\n","parameters = {'n_estimators': [16, 32, 64], \n","              #'max_features': ['log2', 'sqrt','auto'], \n","              #'criterion': ['entropy', 'gini'],\n","              'max_depth': [5, 10, 13], \n","              'min_samples_split': [2, 3, 5],\n","              'min_samples_leaf': [1, 2, 5]\n","             }\n","\n","# Run the grid search\n","grid_obj = GridSearchCV(rfc, parameters, scoring='accuracy', cv=3, n_jobs=10, verbose=1)\n","grid_obj.fit(X, y)\n","\n","# Set the clf to the best combination of parameters\n","rfc = grid_obj.best_estimator_\n","rfc\n","#%%\n","# R"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=13, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=5, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)"},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["rfc = ensemble.RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","            max_depth=13, max_features='auto', max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=5, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, n_estimators=64, n_jobs=-1,\n","            oob_score=False, random_state=None, verbose=0,\n","            warm_start=False)\n","\n","# Fit the best algorithm to the data. \n","rfc.fit(X_train, y_train)\n","\n","#%%\n",""]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Confusion Matrix\n Predicted      0      1    All\nTrue                          \n0          11078   8164  19242\n1           3681  15667  19348\nAll        14759  23831  38590\nRFC:\n               precision    recall  f1-score   support\n\n           0       0.75      0.58      0.65     19242\n           1       0.66      0.81      0.73     19348\n\n   micro avg       0.69      0.69      0.69     38590\n   macro avg       0.70      0.69      0.69     38590\nweighted avg       0.70      0.69      0.69     38590\n\nAUC:  0.692733778598376\nRFC: Input X --> f1: 0.739 (+/- 0.020)\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   14.4s remaining:   14.4s\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   15.1s finished\n"},{"ename":"NameError","evalue":"name 'train' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-3f26af656ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RFC: Input X --> f1: %0.3f (+/- %0.3f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# RFC: Input X --> f1: 0.739 (+/- 0.024)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"]}],"source":["print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('RFC:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","'''\n","Without Under-Sampling:\n","              precision    recall  f1-score   support\n","\n","Under-Sampling:\n","           0       0.75      0.75      0.75     19242\n","           1       0.75      0.75      0.75     19348\n","'''\n","score = cross_val_score(rfc, X, y, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"RFC: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","# RFC: Input X --> f1: 0.739 (+/- 0.024)\n","#%%\n","X_train, X_test, y_train, y_test = train"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"      Iter       Train Loss   Remaining Time \n         1           1.2853           10.88m\n         2           1.2352           10.65m\n         3           1.1922           10.50m\n         4           1.1558           10.37m\n         5           1.1358           10.26m\n         6           1.1182           10.14m\n         7           1.1030           10.03m\n         8           1.0887            9.92m\n         9           1.0751            9.81m\n        10           1.0619            9.70m\n        20           0.9625            8.61m\n        30           0.9062            7.53m\n        40           0.8694            6.46m\n        50           0.8403            5.38m\n        60           0.8164            4.30m\n        70           0.7971            3.23m\n        80           0.7816            2.15m\n        90           0.7671            1.08m\n       100           0.7544            0.00s\nConfusion Matrix\n Predicted      0      1    All\nTrue                          \n0          16293   2949  19242\n1           3427  15921  19348\nAll        19720  18870  38590\nGradBoost:\n               precision    recall  f1-score   support\n\n           0       0.83      0.85      0.84     19242\n           1       0.84      0.82      0.83     19348\n\n   micro avg       0.83      0.83      0.83     38590\n   macro avg       0.83      0.83      0.83     38590\nweighted avg       0.83      0.83      0.83     38590\n\nAUC:  0.8348086261968679\nGradBoost: Input X --> f1: 0.833 (+/- 0.007)\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed: 14.0min remaining: 14.0min\n"},{"name":"stderr","output_type":"stream","text":"[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 14.1min finished\n"},{"data":{"text/plain":"'\\nGradBoost: Input X --> f1: 0.987 (+/- 0.004) - elapsed: 12.4min\\n'"},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Gradient Boosting\n","# We'll make 100 iterations, use 2-deep trees, and set our loss function.\n","params = {'n_estimators': 100,\n","          'max_depth': 2,\n","          'loss': 'deviance',\n","          'verbose': 1,\n","          'n_iter_no_change': 50, \n","          'validation_fraction': 0.1,\n","          'learning_rate': 0.5\n","          }\n","\n","# Initialize and fit the model.\n","gbc = ensemble.GradientBoostingClassifier(**params)\n","gbc.fit(X_train, y_train)\n","\n","y_pred = gbc.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('GradBoost:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","# Best:\n","'''\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","Under-Sampling\n","           0       0.83      0.85      0.84      9682\n","           1       0.84      0.83      0.83      9613\n","'''\n","score = cross_val_score(gbc, X, y, cv=10, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"GradBoost: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","\"\"\"\n","GradBoost: Input X --> f1: 0.987 (+/- 0.004) - elapsed: 12.4min\n","\"\"\"\n","#%%\n","# R"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Reduce dims\n","sklearn_tSVD = TruncatedSVD(n_components=5)\n","X_tSVD = sklearn_tSVD.fit_transform(X)\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tSVD, y, test_size=0.2, random_state=20)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'MinMaxScaler' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-7f985bb67e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# SVM:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"]}],"source":["scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n","X_train = scaling.transform(X_train)\n","X_test = scaling.transform(X_test)\n","# SVM:\n","svc = SVC(gamma='scale', verbose=1)\n","y_test\n","svc.fit(X_train, y_train)\n","\n","y_pred = svc.predict(X_test)\n","print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","print('SVC:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","print('AUC: ', auc(fpr, tpr))\n","'''\n","               precision    recall  f1-score   support\n","           0       0.69      0.82      0.75     19242\n","           1       0.78      0.63      0.70     19348\n","'''\n","score = cross_val_score(svc, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n","print(\"Input X_train --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","# Input X_train --> f1: 0.727 (+/- 0.005)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"k =  5\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.70      0.73      0.71     19242\n           1       0.72      0.68      0.70     19348\n\n   micro avg       0.71      0.71      0.71     38590\n   macro avg       0.71      0.71      0.71     38590\nweighted avg       0.71      0.71      0.71     38590\n\nk =  6\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.70      0.74      0.72     19242\n           1       0.72      0.68      0.70     19348\n\n   micro avg       0.71      0.71      0.71     38590\n   macro avg       0.71      0.71      0.71     38590\nweighted avg       0.71      0.71      0.71     38590\n\nk =  7\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.70      0.75      0.73     19242\n           1       0.73      0.68      0.71     19348\n\n   micro avg       0.72      0.72      0.72     38590\n   macro avg       0.72      0.72      0.72     38590\nweighted avg       0.72      0.72      0.72     38590\n\nk =  8\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.70      0.76      0.73     19242\n           1       0.74      0.68      0.71     19348\n\n   micro avg       0.72      0.72      0.72     38590\n   macro avg       0.72      0.72      0.72     38590\nweighted avg       0.72      0.72      0.72     38590\n\nk =  9\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.76      0.73     19242\n           1       0.74      0.68      0.71     19348\n\n   micro avg       0.72      0.72      0.72     38590\n   macro avg       0.72      0.72      0.72     38590\nweighted avg       0.72      0.72      0.72     38590\n\nk =  10\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.76      0.73     19242\n           1       0.74      0.69      0.71     19348\n\n   micro avg       0.72      0.72      0.72     38590\n   macro avg       0.73      0.72      0.72     38590\nweighted avg       0.73      0.72      0.72     38590\n\nk =  11\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.77      0.74     19242\n           1       0.75      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.73      0.73      0.73     38590\nweighted avg       0.73      0.73      0.73     38590\n\nk =  12\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.77      0.74     19242\n           1       0.75      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.73      0.73      0.73     38590\nweighted avg       0.73      0.73      0.73     38590\n\nk =  13\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.77      0.74     19242\n           1       0.75      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.73      0.73      0.73     38590\nweighted avg       0.73      0.73      0.73     38590\n\nk =  14\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.77      0.74     19242\n           1       0.75      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.73      0.73      0.73     38590\nweighted avg       0.73      0.73      0.73     38590\n\nk =  15\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.78      0.74     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.73      0.73      0.73     38590\nweighted avg       0.73      0.73      0.73     38590\n\nk =  16\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.78      0.74     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.73      0.73      0.73     38590\nweighted avg       0.73      0.73      0.73     38590\n\nk =  17\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.78      0.74     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.73      0.73      0.73     38590\nweighted avg       0.73      0.73      0.73     38590\n\nk =  18\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.78      0.75     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.74      0.73      0.73     38590\nweighted avg       0.74      0.73      0.73     38590\n\nk =  19\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.78      0.75     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.73      0.73      0.73     38590\n   macro avg       0.74      0.73      0.73     38590\nweighted avg       0.74      0.73      0.73     38590\n\nk =  20\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.78      0.75     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.74      0.74      0.74     38590\n   macro avg       0.74      0.74      0.74     38590\nweighted avg       0.74      0.74      0.74     38590\n\nk =  21\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.78      0.75     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.74      0.74      0.74     38590\n   macro avg       0.74      0.74      0.73     38590\nweighted avg       0.74      0.74      0.73     38590\n\nk =  22\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.79      0.75     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.74      0.74      0.74     38590\n   macro avg       0.74      0.74      0.74     38590\nweighted avg       0.74      0.74      0.74     38590\n\nk =  23\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.79      0.75     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.74      0.74      0.74     38590\n   macro avg       0.74      0.74      0.74     38590\nweighted avg       0.74      0.74      0.74     38590\n\nk =  24\nKNN:\n               precision    recall  f1-score   support\n\n           0       0.71      0.79      0.75     19242\n           1       0.76      0.69      0.72     19348\n\n   micro avg       0.74      0.74      0.74     38590\n   macro avg       0.74      0.74      0.74     38590\nweighted avg       0.74      0.74      0.74     38590\n\n"},{"data":{"text/plain":"'\\nWithout Under-Sampling:\\n               precision    recall  f1-score   support\\nk=19\\nUnder-Sampling\\n           0       0.70      0.77      0.74     19242\\n           1       0.75      0.67      0.71     19348\\n'"},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# KNN:\n","for k in range(5, 25, 1):\n","    print('k = ', k)\n","    neighbors = KNeighborsClassifier(n_neighbors=k, n_jobs=-1, weights='distance')\n","    neighbors.fit(X_train, y_train)\n","    y_pred = neighbors.predict(X_test)\n","    #print('Confusion Matrix\\n', pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n","    print('KNN:\\n', classification_report(y_test, y_pred, target_names=['0', '1']))\n","    #fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n","    #print('AUC: ', auc(fpr, tpr))\n","    # Cross Validation\n","    #score = cross_val_score(neighbors, X_test, y_test, cv=5, scoring='accuracy', n_jobs=-1)\n","    #print(\"KNN: Input X --> f1: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n","'''\n","Without Under-Sampling:\n","               precision    recall  f1-score   support\n","k=19\n","Under-Sampling\n","           0       0.70      0.77      0.74     19242\n","           1       0.75      0.67      0.71     19348\n","'''\n","\n","#%% [markdown]\n","# #### Final model evaluation:\n",""]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["\n","#### Other models\n","# * SVM cannot has decent results and is not fast to compute. \n","# * KNN has a similar problem. It gets harder for KNN to process a lot of data points.\n","# * A single Decision tree is not working because vectorized data.\n","# * RandomForest is better but with decent results. \n","# * Naive Bayes is really fast to compute but the results are bad.\n","# * Gradient Boosting the second best model."]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}